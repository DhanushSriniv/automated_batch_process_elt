# Quick Reference Card

## ğŸ“Œ THE ANSWER IN ONE SENTENCE

**Both `bike-share-json` and `gbfs-specification` are identical metadata files pointing to the same live data, extracted 0.15 seconds apartâ€”likely for testing/validation purposes.**

---

## ğŸ¯ FAQ - Quick Answers

### Q: Which data is live?
**A:** All of it. Station data updates every 5-30 seconds. Both metadata files are identical.

### Q: Why two files?
**A:** Appears to be testing/validation. They contain the exact same endpoints and data.

### Q: Can I use just one?
**A:** Yes! Delete `gbfs-specification`, keep `bike-share-json`. They're identical.

### Q: Where's the real station data?
**A:** In the endpoints the metadata points to:
- `station_information` (510 KB, 1,008 stations)
- `station_status` (337 KB, real-time availability)

### Q: How often do they update?
**A:** 
- Metadata: Once per batch job (~hourly or on-demand)
- Station status: Every 5-30 seconds (real-time)

### Q: What size is the data?
**A:** 
- Metadata: 1-2 KB
- Station data: 300-500 KB per endpoint
- Total: ~856 KB per extraction

### Q: How many stations?
**A:** 1,008 stations in Toronto Bike Share system

---

## ğŸš€ RUN THE ANALYSIS

```bash
# From project root
python testing/data_source_analysis.py          # 1 sec
python testing/live_data_endpoint_analysis.py   # 5-10 sec
python testing/detailed_data_structure.py       # 3-5 sec
python testing/extraction_data_testing.py       # 1 sec
```

---

## ğŸ“Š DATA LAYOUT

```
Live Source (API)
    â†“ (extracts to)
Metadata (feeds_summary.json)
    â”œâ”€ Size: 1-2 KB
    â”œâ”€ Purpose: Tell you WHERE data is
    â””â”€ Contains: 5 endpoint URLs
        â†“ (fetches from)
Actual Data (station_information, status, etc.)
    â”œâ”€ Size: 300-500 KB per endpoint
    â”œâ”€ Purpose: Give you the REAL data
    â””â”€ Contains: 1,008 stations + status
```

---

## ğŸ”‘ KEY FILES STRUCTURE

```
bike-share-json/
â”œâ”€ feeds_summary.json         â† Metadata (1-2 KB)
â”œâ”€ station_information.json   â† Live data (510 KB)
â”œâ”€ station_status.json        â† Real-time (337 KB)
â”œâ”€ system_information.json    â† System meta (0.42 KB)
â”œâ”€ system_pricing_plans.json  â† Pricing (8.43 KB)
â””â”€ system_regions.json        â† Regions (0.06 KB)

gbfs-specification/
â””â”€ (identical files)
```

---

## ğŸ“ˆ DATA PIPELINE SEQUENCE

1. **Extract metadata** â†’ feeds_summary.json (URLs)
2. **Fetch live data** â†’ Using URLs from metadata
3. **Store in BRONZE** â†’ Raw JSON snapshots
4. **Transform in SILVER** â†’ Structured tables
5. **Analyze in GOLD** â†’ Business dashboards

---

## ğŸ§ª TESTING SCRIPTS

| Script | Purpose | Time | Output |
|--------|---------|------|--------|
| `data_source_analysis.py` | Compare metadata | 1s | Comparison tables |
| `live_data_endpoint_analysis.py` | Fetch live data | 5-10s | Data sizes, response times |
| `detailed_data_structure.py` | Show actual data | 3-5s | Sample stations + schema |
| `extraction_data_testing.py` | Find differences | 1s | JSON diffs |

---

## ğŸ’¾ ACTUAL DATA SAMPLE

```json
{
  "station_id": "7000",
  "name": "Fort York  Blvd / Capreol Ct",
  "lat": 43.639832,
  "lon": -79.395954,
  "capacity": 47,
  "num_bikes_available": 32,
  "num_docks_available": 14,
  "status": "IN_SERVICE",
  "is_renting": 1,
  "is_returning": 1
}
```

---

## âš¡ ONE-LINE COMMANDS

```bash
# See what's in both files
python testing/data_source_analysis.py

# Check if endpoints are live
python testing/live_data_endpoint_analysis.py

# See actual bike station data
python testing/detailed_data_structure.py

# Compare the two metadata files
python testing/extraction_data_testing.py
```

---

## ğŸ“ KEY INSIGHTS

1. âœ“ **Same Source** â†’ Both point to identical live endpoints
2. âœ“ **Same Data** â†’ URLs produce identical results
3. âœ“ **Live Updates** â†’ Station status updates every 5-30s
4. âœ“ **Metadata First** â†’ Must read metadata to find endpoint URLs
5. âœ“ **1,008 Stations** â†’ Toronto Bike Share coverage
6. âœ“ **Real-time** â†’ Can build live dashboards
7. âœ“ **856 KB** â†’ Total data per extraction (~every batch)

---

## ğŸ“š DOCUMENTATION

- **DATA_SOURCE_EXPLANATION.md** â†’ Comprehensive guide
- **README.md** â†’ How to run scripts  
- **ANALYSIS_COMPLETE.txt** â†’ Full summary report
- **testing/data_source_analysis.py** â†’ See it yourself
- **utils/el_global.py** â†’ Reusable functions

---

## âœ… CHECKLIST

- [x] Understand which data is live (Answer: All of it)
- [x] Understand why two files (Answer: Testing/validation)
- [x] Create testing scripts (Answer: 4 scripts created)
- [x] Fetch live endpoint data (Answer: All working)
- [x] Show actual data samples (Answer: Displayed)
- [x] Provide architecture insight (Answer: Documented)
- [x] Document in testing folder (Answer: Complete)

---

## ğŸ”— CONNECTED SYSTEMS

```
el_global.py (module)
    â”œâ”€ load_json_from_file()      â†’ Load local JSON
    â”œâ”€ fetch_json()               â†’ Fetch from URL
    â””â”€ compare_json()             â†’ Compare two objects
    
Used by ALL scripts:
    â”œâ”€ data_source_analysis.py
    â”œâ”€ live_data_endpoint_analysis.py
    â”œâ”€ detailed_data_structure.py
    â””â”€ extraction_data_testing.py
```

---

## ğŸ¬ NEXT STEPS

1. Run `python testing/data_source_analysis.py` to see comparison
2. Run `python testing/live_data_endpoint_analysis.py` to see live data
3. Run `python testing/detailed_data_structure.py` to see actual stations
4. Read `testing/DATA_SOURCE_EXPLANATION.md` for deep dive
5. Decide: Keep one metadata file or both?
6. Plan: How to process the 1,008 stations?
7. Build: Transformation layer (SILVER) for your needs

---

**Status:** âœ“ COMPLETE  
**Created:** 2026-02-20  
**Location:** `testing/` folder  
**Scripts:** 4 comprehensive analysis scripts  
**Documentation:** 3 guide documents + this card
